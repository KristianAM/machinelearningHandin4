{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(x, y, group, fmt='.', **kwargs):\n",
    "    \"\"\"\n",
    "    Given two d-dimensional datasets of n points,\n",
    "    makes a figure containing d x d plots, where the (i, j) plot\n",
    "    plots the ith dimension against the jth dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    group = np.squeeze(np.asarray(group))\n",
    "    n, p = x.shape\n",
    "    n_, q = y.shape\n",
    "    n__, = group.shape\n",
    "    assert n == n_ == n__\n",
    "    groups = sorted(set(group))\n",
    "    if isinstance(fmt, str):\n",
    "        fmt = {k: fmt for k in groups}\n",
    "    fig, axes = plt.subplots(p, q, squeeze=False, **kwargs)\n",
    "    for i, axrow in enumerate(axes):\n",
    "        for j, ax in enumerate(axrow):\n",
    "            for g in groups:\n",
    "                ax.plot(x[group == g, i], y[group == g, j], fmt[g])\n",
    "            if len(axes) > 2:\n",
    "                ax.locator_params(tight=True, nbins=4)\n",
    "\n",
    "def plot_groups(x, group, fmt='.', **kwargs):\n",
    "    \"\"\"\n",
    "    Helper function for plotting a 2-dimensional dataset with groups\n",
    "    using plot_matrix.\n",
    "    \"\"\"\n",
    "    n, d = x.shape\n",
    "    assert d == 2\n",
    "    x1 = x[:, 0].reshape(n, 1)\n",
    "    x2 = x[:, 1].reshape(n, 1)\n",
    "    plot_matrix(x1, x2, group, fmt, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "iris = sklearn.datasets.load_iris()\n",
    "data = iris['data']\n",
    "labels = iris['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "def pdf(points, mean, cov, prior):\n",
    "    points, mean, cov = np.asarray(points), np.asarray(mean), np.asarray(cov)\n",
    "    prior = np.asarray(prior)\n",
    "    n, d = points.shape\n",
    "    k, d_1 = mean.shape\n",
    "    k_2, d_2, d_3 = cov.shape\n",
    "    k_3, = prior.shape\n",
    "    assert d == d_1 == d_2 == d_3\n",
    "    assert k == k_2 == k_3, \"%s %s %s should be equal\" % (k, k_2, k_3)\n",
    "\n",
    "    # Compute probabilities\n",
    "    prob = []\n",
    "    for i in range(k):\n",
    "        if prior[i] < 1 / k ** 3:\n",
    "            prob.append(np.zeros(n))\n",
    "        else:\n",
    "#            print(\"pdf mean \",mean[i])\n",
    "#            print(\"pdf cov \",cov[i])\n",
    "            prob.append(\n",
    "                prior[i] *\n",
    "                multivariate_normal.pdf(\n",
    "                    mean=mean[i], cov=cov[i], x=points))\n",
    "    prob = np.transpose(prob)  # n x k\n",
    "    # Normalize cluster probabilities of each point\n",
    "    prob = prob / np.sum(prob, axis=1, keepdims=True)  # n x k\n",
    "\n",
    "    assert prob.shape == (n, k)\n",
    "    assert np.allclose(prob.sum(axis=1), 1)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_likely(points, mean, cov, prior):\n",
    "    prob = pdf(points, mean, cov, prior)\n",
    "    return np.argmax(prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def em(points, k, epsilon, mean=None):\n",
    "    points = np.asarray(points)\n",
    "    n, d = points.shape\n",
    "\n",
    "    # Initialize and validate mean\n",
    "    if mean is None:\n",
    "        # Randomly pick k points\n",
    "        maximum = np.amax(points, axis = 0)\n",
    "        minimum = np.amin(points, axis = 0)\n",
    "        mean = np.zeros((k,d))\n",
    "        for i in range(k):\n",
    "            for j in range(d):\n",
    "                mean[i,j] = np.random.uniform(minimum[j], maximum[j])\n",
    "\n",
    "    # Validate input\n",
    "    mean = np.asarray(mean)\n",
    "    k_, d_ = mean.shape\n",
    "    assert k == k_\n",
    "    assert d == d_\n",
    "\n",
    "    # Initialize cov, prior\n",
    "    cov = np.array([np.eye(d) for x in range(k)])\n",
    "    prior = np.array([1/k for x in range(k)])\n",
    "\n",
    "    tired = False\n",
    "    old_mean = np.zeros_like(mean)\n",
    "    while not tired:\n",
    "        old_mean[:] = mean\n",
    "\n",
    "        # Expectation step\n",
    " #       print(\"--------------------------------\")\n",
    " #       print(\"Emean \",mean)\n",
    " #       print(\"Ecov \",cov)\n",
    " #       print(\"Eprior \",prior)\n",
    "        weights=pdf(points, mean, cov, prior)\n",
    " #       print (\"weights \",weights)\n",
    "        # Maximization step\n",
    "        weights_sum=np.sum(weights,axis=0)\n",
    " #       print(\"sum\",weights_sum)\n",
    "        for i in range(k):\n",
    "            res=weights[:,i].reshape(n,1)*points\n",
    "            mean[i]=np.sum(res,axis=0)/weights_sum[i]\n",
    "            new_cov=np.zeros([d,d])\n",
    "            for j in range(n):\n",
    "                new_cov+=weights[j,i]*np.outer(points[j]-mean[i],points[j]-mean[i])\n",
    "            cov[i]=new_cov/weights_sum[i]\n",
    "        prior[:]=weights_sum/n    \n",
    "                    \n",
    "\n",
    "        # Finish condition\n",
    "        dist = np.sqrt(((mean - old_mean) ** 2).sum(axis=1))\n",
    "        tired = np.all(dist < epsilon)\n",
    "\n",
    "    # Validate output\n",
    "    assert mean.shape == (k, d)\n",
    "    assert cov.shape == (k, d, d)\n",
    "    assert prior.shape == (k,)\n",
    "    return mean, cov, prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.64084012  0.19052331]\n",
      " [ 0.48520361 -0.12609158]\n",
      " [ 1.44765296 -0.09056442]]\n",
      "[[[ 0.04777048  0.05590727]\n",
      "  [ 0.05590727  0.21472044]]\n",
      "\n",
      " [[ 0.18269699  0.19662482]\n",
      "  [ 0.19662482  0.21385676]]\n",
      "\n",
      " [[ 1.04886054  0.36815436]\n",
      "  [ 0.36815436  0.22809615]]]\n",
      "[ 0.33333233  0.08813558  0.57853209]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "import sklearn.decomposition\n",
    "tmean=np.array([[-3.59,0.25],[-1.09,-0.46],[0.75,1.07]])\n",
    "pca = sklearn.decomposition.PCA(2)\n",
    "data_pca = pca.fit_transform(data)\n",
    "rmean,rcov,rprior=em(data_pca,3,0.001,mean=tmean)\n",
    "print(rmean)\n",
    "print(rcov)\n",
    "print(rprior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Emean  [[ 4.56820839  2.53595853]\n",
      " [ 2.08299319  2.78803037]]\n",
      "Ecov  [[[ 1.  0.]\n",
      "  [ 0.  1.]]\n",
      "\n",
      " [[ 1.  0.]\n",
      "  [ 0.  1.]]]\n",
      "Eprior  [ 0.5  0.5]\n",
      "pdf mean  [ 4.56820839  2.53595853]\n",
      "pdf cov  [[ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "pdf mean  [ 2.08299319  2.78803037]\n",
      "pdf cov  [[ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "weights  [[  1.71100173e-03   9.98288998e-01]\n",
      " [  5.33800177e-02   9.46619982e-01]\n",
      " [  9.78625886e-01   2.13741141e-02]\n",
      " [  9.99992373e-01   7.62738277e-06]]\n",
      "sum [ 2.03370928  1.96629072]\n",
      "--------------------------------\n",
      "Emean  [[ 6.39301772  2.93868125]\n",
      " [ 1.52493246  3.0634212 ]]\n",
      "Ecov  [[[ 2.73456884 -1.23895261]\n",
      "  [-1.23895261  1.07750682]]\n",
      "\n",
      " [[ 0.37998455 -0.95268636]\n",
      "  [-0.95268636  3.9633553 ]]]\n",
      "Eprior  [ 0.50842732  0.49157268]\n",
      "pdf mean  [ 6.39301772  2.93868125]\n",
      "pdf cov  [[ 2.73456884 -1.23895261]\n",
      " [-1.23895261  1.07750682]]\n",
      "pdf mean  [ 1.52493246  3.0634212 ]\n",
      "pdf cov  [[ 0.37998455 -0.95268636]\n",
      " [-0.95268636  3.9633553 ]]\n",
      "weights  [[  4.63292361e-03   9.95367076e-01]\n",
      " [  1.08514517e-08   9.99999989e-01]\n",
      " [  1.00000000e+00   4.61666437e-20]\n",
      " [  1.00000000e+00   5.02426738e-56]]\n",
      "sum [ 2.00463293  1.99536707]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 6.48728888,  3.00462221],\n",
       "        [ 1.50116092,  2.99535633]]), array([[[ 2.31454955, -1.52189672],\n",
       "         [-1.52189672,  1.00691198]],\n",
       " \n",
       "        [[ 0.24999865, -0.99999461],\n",
       "         [-0.99999461,  3.99997844]]]), array([ 0.50115823,  0.49884177]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[1,5],[2,1],[5,4],[8,2]])\n",
    "em(a,2,0.5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
